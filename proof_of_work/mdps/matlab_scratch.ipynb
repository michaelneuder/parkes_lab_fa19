{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ss.SparseEfficiencyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.3\n",
      "processing state 0\n",
      "processing state 2000\n",
      "processing state 4000\n",
      "processing state 6000\n",
      "processing state 8000\n",
      "processing state 10000\n",
      "processing state 12000\n",
      "processing state 14000\n",
      "processing state 16000\n",
      "alpha:  0.3 lower bound reward: 0.29999542236328125\n",
      "alpha:  0.3 upper bound reward 0.30000762939453124\n",
      "alpha:  0.35\n",
      "processing state 0\n",
      "processing state 2000\n",
      "processing state 4000\n",
      "processing state 6000\n",
      "processing state 8000\n",
      "processing state 10000\n",
      "processing state 12000\n",
      "processing state 14000\n",
      "processing state 16000\n",
      "alpha:  0.35 lower bound reward: 0.37076568603515625\n",
      "alpha:  0.35 upper bound reward 0.37077789306640624\n",
      "alpha:  0.4\n",
      "processing state 0\n",
      "processing state 2000\n",
      "processing state 4000\n",
      "processing state 6000\n",
      "processing state 8000\n",
      "processing state 10000\n",
      "processing state 12000\n",
      "processing state 14000\n",
      "processing state 16000\n",
      "alpha:  0.4 lower bound reward: 0.48863983154296875\n",
      "alpha:  0.4 upper bound reward 0.48865203857421874\n",
      "alpha:  0.45\n",
      "processing state 0\n",
      "processing state 2000\n",
      "processing state 4000\n",
      "processing state 6000\n",
      "processing state 8000\n",
      "processing state 10000\n",
      "processing state 12000\n",
      "processing state 14000\n",
      "processing state 16000\n",
      "alpha:  0.45 lower bound reward: 0.6681442260742188\n",
      "alpha:  0.45 upper bound reward 0.6705490112304688\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for alpha in np.linspace(0.3, 0.45, 4):\n",
    "    result = []\n",
    "    maxForkLen = 75\n",
    "    numOfStates = (maxForkLen+1) * (maxForkLen+1) * 3\n",
    "    print('alpha: ', alpha)\n",
    "    result.append(alpha)\n",
    "    alphaPower = alpha\n",
    "    gammaRatio = 0\n",
    "    irrelevant = 0; relevant = 1; active = 2;\n",
    "    choices = 4\n",
    "    adopt = 0; override = 1; match = 2; wait = 3;\n",
    "    P = []; Rs = []; Rh = [];\n",
    "    for _ in range(choices):\n",
    "        P.append(ss.csr_matrix(np.zeros(shape=(numOfStates, numOfStates))))\n",
    "        Rs.append(ss.csr_matrix(np.zeros(shape=(numOfStates, numOfStates))))\n",
    "        Rh.append(ss.csr_matrix(np.zeros(shape=(numOfStates, numOfStates))))\n",
    "    # generate a state to integer mapping and list of states\n",
    "    state_mapping = {}\n",
    "    states = []\n",
    "    count = 0\n",
    "    for a in range(maxForkLen+1):\n",
    "        for h in range(maxForkLen+1):\n",
    "            for fork in range(3):\n",
    "                state_mapping[(a, h, fork)] = count\n",
    "                states.append((a, h, fork))\n",
    "                count += 1\n",
    "    # adopt\n",
    "    P[adopt][:, state_mapping[1, 0, irrelevant]] = alphaPower\n",
    "    P[adopt][:, state_mapping[0, 1, irrelevant]] = 1 - alphaPower\n",
    "    for state_index in range(numOfStates):\n",
    "        if state_index % 2000 == 0:\n",
    "            print('processing state', state_index)\n",
    "        a, h, fork = states[state_index]\n",
    "\n",
    "        # adopt rewards\n",
    "        Rh[adopt][state_index, state_mapping[1, 0, irrelevant]] = h\n",
    "        Rh[adopt][state_index, state_mapping[0, 1, irrelevant]] = h\n",
    "\n",
    "        # override\n",
    "        if a > h:\n",
    "            P[override][state_index, state_mapping[a-h, 0, irrelevant]] = alphaPower\n",
    "            Rs[override][state_index, state_mapping[a-h, 0, irrelevant]] = h+1\n",
    "            P[override][state_index, state_mapping[a-h-1, 1, relevant]] = 1 - alphaPower\n",
    "            Rs[override][state_index, state_mapping[a-h-1, 1, relevant]] = h+1\n",
    "        else:\n",
    "            P[override][state_index, 0] = 1\n",
    "            Rh[override][state_index, 0] = 10000\n",
    "\n",
    "        # wait\n",
    "        if (fork != active) and (a < maxForkLen) and (h < maxForkLen):\n",
    "            P[wait][state_index, state_mapping[a+1, h, irrelevant]] = alphaPower\n",
    "            P[wait][state_index, state_mapping[a, h+1, relevant]] = 1 - alphaPower\n",
    "        elif (fork == active) and (a > h) and (h > 0) and (a < maxForkLen) and (h < maxForkLen): \n",
    "            P[wait][state_index, state_mapping[a+1, h, active]] = alphaPower\n",
    "            P[wait][state_index, state_mapping[a-h, 1, relevant]] = gammaRatio*(1-alphaPower)\n",
    "            Rs[wait][state_index, state_mapping[a-h, 1, relevant]] = h\n",
    "            P[wait][state_index, state_mapping[a, h+1, relevant]] = (1-gammaRatio)*(1-alphaPower)\n",
    "        else:\n",
    "            P[wait][state_index, 0] = 1\n",
    "            Rh[wait][state_index, 0] = 10000\n",
    "\n",
    "        # match\n",
    "        if (fork == relevant) and (a >= h) and (h > 0) and (a < maxForkLen) and (h < maxForkLen):\n",
    "            P[match][state_index, state_mapping[a+1, h, active]] = alphaPower\n",
    "            P[match][state_index, state_mapping[a-h, 1, relevant]] = gammaRatio*(1-alphaPower)\n",
    "            Rs[match][state_index, state_mapping[a-h, 1, relevant]] = h\n",
    "            P[match][state_index, state_mapping[a, h+1, relevant]] = (1-gammaRatio)*(1-alphaPower)\n",
    "        else:\n",
    "            P[match][state_index, 0] = 1\n",
    "            Rh[match][state_index, 0] = 10000\n",
    "    epsilon = 0.0001\n",
    "    lowRho = 0\n",
    "    highRho = 1\n",
    "    while(highRho - lowRho > epsilon/8):\n",
    "        rho = (highRho + lowRho) / 2;\n",
    "        Wrho = []\n",
    "        for i in range(choices):\n",
    "            Wrho.append((1-rho)*Rs[i] - rho*Rh[i])\n",
    "        rvi = mdptoolbox.mdp.RelativeValueIteration(P, Wrho, epsilon/8)\n",
    "        rvi.run()\n",
    "        lowerBoundPolicy = rvi.policy\n",
    "        reward = rvi.average_reward\n",
    "        if reward > 0:\n",
    "            lowRho = rho\n",
    "        else:\n",
    "            highRho = rho\n",
    "    print('alpha: ', alphaPower, 'lower bound reward:', rho)\n",
    "    result.append(rho)\n",
    "    lowerBoundRho = rho\n",
    "    lowRho = rho\n",
    "    highRho = min(rho+0.1, 1)\n",
    "    while (highRho - lowRho) > (epsilon / 8):\n",
    "        rho = (highRho + lowRho) / 2\n",
    "        for state_index in range(numOfStates):\n",
    "            a, h, fork = states[state_index]\n",
    "            if a == maxForkLen:\n",
    "                expr = (1-rho)*alphaPower*(1-alphaPower)/(1-2*alphaPower)**2+0.5*((a-h)/(1-2*alphaPower)+a+h)\n",
    "                Rs[adopt][state_index, state_mapping[1, 0, irrelevant]] = expr\n",
    "                Rs[adopt][state_index, state_mapping[0, 1, irrelevant]] = expr\n",
    "                Rs[adopt][state_index, state_mapping[1, 0, irrelevant]] = 0\n",
    "                Rs[adopt][state_index, state_mapping[0, 1, irrelevant]] = 0\n",
    "            elif h == maxForkLen:\n",
    "                expr1 = (1 - np.power(alphaPower/(1-alphaPower), h - a)) * (-1*rho*h)\n",
    "                expr2 = np.power(alphaPower/(1-alphaPower), h - a) * (1 - rho)\n",
    "                expr3 = (alphaPower * (1-alphaPower)) / (np.power(1-2*alphaPower, 2)) + (h - a) / (1- 2 * alphaPower)\n",
    "                expr_total = expr1 + expr2 * expr3\n",
    "                Rs[adopt][state_index, state_mapping[1, 0, irrelevant]] = expr_total\n",
    "                Rs[adopt][state_index, state_mapping[0, 1, irrelevant]] = expr_total\n",
    "                Rh[adopt][state_index, state_mapping[1, 0, irrelevant]] = 0\n",
    "                Rh[adopt][state_index, state_mapping[0, 1, irrelevant]] = 0\n",
    "        Wrho = []\n",
    "        for i in range(choices):\n",
    "            Wrho.append((1-rho)*Rs[i] - rho*Rh[i])\n",
    "        rhoPrime = max(lowRho - epsilon/4, 0)\n",
    "        rvi = mdptoolbox.mdp.RelativeValueIteration(P, Wrho, epsilon/8)\n",
    "        rvi.run()\n",
    "        reward = rvi.average_reward\n",
    "        policy = rvi.policy\n",
    "        if reward > 0:\n",
    "            lowRho = rho\n",
    "        else:\n",
    "            highRho = rho\n",
    "    print('alpha: ', alphaPower, 'upper bound reward', rho)\n",
    "    result.append(rho)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.3, 0.29999542236328125, 0.30000762939453124],\n",
       " [0.35, 0.37076568603515625, 0.37077789306640624],\n",
       " [0.4, 0.48863983154296875, 0.48865203857421874],\n",
       " [0.45, 0.6681442260742188, 0.6705490112304688]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275  & 0.30000 & 0.30001 \\\\\n",
      "0.3  & 0.37077 & 0.37078 \\\\\n",
      "0.325  & 0.48864 & 0.48865 \\\\\n",
      "0.35  & 0.66814 & 0.67055 \\\\\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "linspace = [0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3, 0.325, 0.35, 0.375, 0.4, 0.425, 0.45, 0.475]\n",
    "for result in results:\n",
    "    print(linspace[i], ' & {0:.5f} & {1:.5f} \\\\\\\\'.format(result[1], result[2]))\n",
    "    i +=1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
