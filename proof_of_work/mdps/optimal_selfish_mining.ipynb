{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdoptMatrices(rho, underpaying=True):\n",
    "    # creating the adopt transition & reward matrices\n",
    "    adopt_transitions = np.zeros(shape = (num_states, num_states))\n",
    "    adopt_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "    # each adopt matrix only can map to (1,0,irrelevant) or (0,1,irrelevant)\n",
    "    adopt_new_state_1_index = state_mapping[(1, 0, 'irrelevant')]\n",
    "    adopt_new_state_2_index = state_mapping[(0, 1, 'irrelevant')]\n",
    "    for state_index in range(num_states):\n",
    "        state = states[state_index]\n",
    "        adopt_transitions[state_index, adopt_new_state_1_index] = alpha\n",
    "        adopt_transitions[state_index, adopt_new_state_2_index] = 1 - alpha\n",
    "        adopt_rewards[state_index, adopt_new_state_1_index] = rho * state[1]\n",
    "        adopt_rewards[state_index, adopt_new_state_2_index] = rho * state[1]\n",
    "        if ((state[0] == T) or (state[1] == T)) and (state[0] != state[1]):\n",
    "            # overpaying\n",
    "            if not underpaying:\n",
    "                # attacker ahead\n",
    "                if state[0] > state[1]: \n",
    "                    adopt_rewards[state_index, adopt_new_state_1_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                    adopt_rewards[state_index, adopt_new_state_2_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                # honest ahead\n",
    "                else: \n",
    "                    adopt_rewards[state_index, adopt_new_state_1_index] = overpayHonestAhead(state[0], state[1], rho)\n",
    "                    adopt_rewards[state_index, adopt_new_state_2_index] = overpayHonestAhead(state[0], state[1], rho)\n",
    "    \n",
    "    # making matrices sparse\n",
    "    return ss.csr_matrix(adopt_transitions), ss.csr_matrix(adopt_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverrideMatrices(rho, underpaying=True):\n",
    "    # creating the override transition & reward matrices\n",
    "    override_transitions = np.zeros(shape = (num_states, num_states))\n",
    "    override_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "    for state_index in range(num_states):\n",
    "        state = states[state_index]\n",
    "        # checking if we are at the max fork length.\n",
    "        if ((state[0] == T) or (state[1] == T)) and (state[0] != state[1]):\n",
    "            adopt_new_state_1_index = state_mapping[(1, 0, 'irrelevant')]\n",
    "            adopt_new_state_2_index = state_mapping[(0, 1, 'irrelevant')]\n",
    "            override_transitions[state_index, adopt_new_state_1_index] = alpha\n",
    "            override_transitions[state_index, adopt_new_state_2_index] = 1 - alpha\n",
    "            if underpaying:\n",
    "                override_rewards[state_index, adopt_new_state_1_index] = rho * state[1]\n",
    "                override_rewards[state_index, adopt_new_state_2_index] = rho * state[1]\n",
    "            else:\n",
    "               # attacker ahead\n",
    "                if state[0] > state[1]: \n",
    "                    override_rewards[state_index, adopt_new_state_1_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                    override_rewards[state_index, adopt_new_state_2_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                # honest ahead\n",
    "                else: \n",
    "                    override_rewards[state_index, adopt_new_state_1_index] = overpayHonestAhead(state[0], state[1], rho)\n",
    "                    override_rewards[state_index, adopt_new_state_2_index] = overpayHonestAhead(state[0], state[1], rho) \n",
    "            continue\n",
    "            \n",
    "        # a > h, which must be true for override to succeed\n",
    "        if state[0] > state[1]:\n",
    "            # (a-h, 0, irrelevant)\n",
    "            new_state_1 = (state[0]-state[1], 0, 'irrelevant')\n",
    "            # (a-h-1, 1, relevant)\n",
    "            new_state_2 = (state[0]-state[1]-1, 1, 'relevant')\n",
    "            override_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "            override_transitions[state_index, state_mapping[new_state_2]] = 1 - alpha\n",
    "            override_rewards[state_index, state_mapping[new_state_1]] = (1 - rho) * (state[1] + 1)\n",
    "            override_rewards[state_index, state_mapping[new_state_2]] = (1 - rho) * (state[1] + 1)\n",
    "        else:\n",
    "            # filling in remainder of array.\n",
    "            override_transitions[state_index, 0] = 1\n",
    "            override_rewards[state_index, 0] = -1*rho*1000\n",
    "\n",
    "    # making matrices sparse\n",
    "    return ss.csr_matrix(override_transitions), ss.csr_matrix(override_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWaitMatrices(rho, underpaying=True):\n",
    "    # creating the wait transition & reward matrices\n",
    "    wait_transitions = np.zeros(shape = (num_states, num_states))\n",
    "    wait_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "    for state_index in range(num_states):\n",
    "        state = states[state_index]\n",
    "        # checking if we are at the max fork length.\n",
    "        if ((state[0] == T) or (state[1] == T)) and (state[0] != state[1]):\n",
    "            adopt_new_state_1_index = state_mapping[(1, 0, 'irrelevant')]\n",
    "            adopt_new_state_2_index = state_mapping[(0, 1, 'irrelevant')]\n",
    "            wait_transitions[state_index, adopt_new_state_1_index] = alpha\n",
    "            wait_transitions[state_index, adopt_new_state_2_index] = 1 - alpha\n",
    "            if underpaying:\n",
    "                wait_rewards[state_index, adopt_new_state_1_index] = rho * state[1]\n",
    "                wait_rewards[state_index, adopt_new_state_2_index] = rho * state[1]\n",
    "            else:\n",
    "               # attacker ahead\n",
    "                if state[0] > state[1]: \n",
    "                    wait_rewards[state_index, adopt_new_state_1_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                    wait_rewards[state_index, adopt_new_state_2_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                # honest ahead\n",
    "                else: \n",
    "                    wait_rewards[state_index, adopt_new_state_1_index] = overpayHonestAhead(state[0], state[1], rho)\n",
    "                    wait_rewards[state_index, adopt_new_state_2_index] = overpayHonestAhead(state[0], state[1], rho) \n",
    "        \n",
    "        # irrelevant or relevant\n",
    "        elif ((state[2] == 'irrelevant') or (state[2] == 'relevant')) and (state[0]<T) and (state[1]<T):\n",
    "            # (a+1, h, irrelevant)\n",
    "            new_state_1 = (state[0] + 1, state[1], 'irrelevant')\n",
    "            # (a, h+1, relevant)\n",
    "            new_state_2 = (state[0], state[1] + 1, 'relevant')\n",
    "            wait_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "            wait_transitions[state_index, state_mapping[new_state_2]] = 1 - alpha\n",
    "        # active\n",
    "        elif (state[2] == 'active') and (state[0]<T) and (state[1]<T) and (state[1]>0):\n",
    "            # a >= h\n",
    "            if state[0] >= state[1]: \n",
    "                # (a+1, h, active)\n",
    "                new_state_1 = (state[0] + 1, state[1], 'active')\n",
    "                # (a-h, 1, relevant)\n",
    "                new_state_2 = (state[0] - state[1], 1, 'relevant')\n",
    "                # (a, h+1, relevant)\n",
    "                new_state_3 = (state[0], state[1] + 1, 'relevant')\n",
    "                wait_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "                wait_transitions[state_index, state_mapping[new_state_2]] = gamma * (1 - alpha)\n",
    "                wait_transitions[state_index, state_mapping[new_state_3]] = (1 - gamma) * (1 - alpha)\n",
    "                wait_rewards[state_index, state_mapping[new_state_2]] = (1 - rho) * state[1]\n",
    "            else:\n",
    "                wait_transitions[state_index, 0] = 1\n",
    "                wait_rewards[state_index, 0] = -1*rho*1000\n",
    "        else:\n",
    "            wait_transitions[state_index, 0] = 1\n",
    "            wait_rewards[state_index, 0] = -1*rho*1000\n",
    "\n",
    "    # making matrices sparse\n",
    "    return ss.csr_matrix(wait_transitions), ss.csr_matrix(wait_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatchMatrices(rho, underpaying=True):\n",
    "    # creating the match transition & rewards matrices\n",
    "    match_transitions = np.zeros(shape = (num_states, num_states))\n",
    "    match_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "    for state_index in range(num_states):\n",
    "        state = states[state_index]\n",
    "        # checking if we are at the max fork length.\n",
    "        if ((state[0] == T) or (state[1] == T)) and (state[0] != state[1]):\n",
    "            adopt_new_state_1_index = state_mapping[(1, 0, 'irrelevant')]\n",
    "            adopt_new_state_2_index = state_mapping[(0, 1, 'irrelevant')]\n",
    "            match_transitions[state_index, adopt_new_state_1_index] = alpha\n",
    "            match_transitions[state_index, adopt_new_state_2_index] = 1 - alpha\n",
    "            if underpaying:\n",
    "                match_rewards[state_index, adopt_new_state_1_index] = rho * state[1]\n",
    "                match_rewards[state_index, adopt_new_state_2_index] = rho * state[1]\n",
    "            else:\n",
    "               # attacker ahead\n",
    "                if state[0] > state[1]: \n",
    "                    match_rewards[state_index, adopt_new_state_1_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                    match_rewards[state_index, adopt_new_state_2_index] = overpayAttackerAhead(state[0], state[1], rho)\n",
    "                # honest ahead\n",
    "                else: \n",
    "                    match_rewards[state_index, adopt_new_state_1_index] = overpayHonestAhead(state[0], state[1], rho)\n",
    "                    match_rewards[state_index, adopt_new_state_2_index] = overpayHonestAhead(state[0], state[1], rho) \n",
    "            continue\n",
    "\n",
    "        # a >= h and relevant\n",
    "        if (state[0] >= state[1]) and (state[2] == 'relevant') and (state[0]<T) and (state[1]<T) and (state[1]>0):\n",
    "            # (a+1, h, active)\n",
    "            new_state_1 = (state[0] + 1, state[1], 'active')\n",
    "            # (a-h, 1, relevant)\n",
    "            new_state_2 = (state[0] - state[1], 1, 'relevant')\n",
    "            # (a, h+1, relevant)\n",
    "            new_state_3 = (state[0], state[1] + 1, 'relevant')\n",
    "            match_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "            match_transitions[state_index, state_mapping[new_state_2]] = gamma * (1 - alpha)\n",
    "            match_transitions[state_index, state_mapping[new_state_3]] = (1 - gamma) * (1 - alpha)\n",
    "            match_rewards[state_index, state_mapping[new_state_2]] = (1 - rho) * state[1]\n",
    "        else:\n",
    "            match_transitions[state_index, 0] = 1\n",
    "            match_rewards[state_index, 0] = -1*rho*1000\n",
    "\n",
    "    # making matrices sparse\n",
    "    return ss.csr_matrix(match_transitions), ss.csr_matrix(match_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overpayAttackerAhead(a, h, rho):\n",
    "    assert(a > h)\n",
    "    expr1 = (1 - rho) * (alpha * (1 - alpha)) / ((1 - 2 * alpha)**2)\n",
    "    expr2 = (1/2) * ((a - h) / (1 - 2 * alpha) + a + h)\n",
    "    return expr1 + expr2\n",
    "\n",
    "def overpayHonestAhead(a, h, rho):\n",
    "    assert(h > a)\n",
    "    expr1 = (1 - np.power(alpha/(1-alpha), h - a)) * (-1*rho*h)\n",
    "    expr2 = np.power(alpha/(1-alpha), h - a) * (1 - rho)\n",
    "    expr3 = (alpha * (1-alpha)) / (np.power(1-2*alpha, 2)) + (h - a) / (1- 2 * alpha)\n",
    "    return expr1 + expr2 * expr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllMatrices(rho, underpaying=True):\n",
    "    adopt = getAdoptMatrices(rho, underpaying)\n",
    "    override = getOverrideMatrices(rho, underpaying)\n",
    "    wait = getWaitMatrices(rho, underpaying)\n",
    "    match = getMatchMatrices(rho, underpaying)\n",
    "    return [adopt[0], override[0], wait[0], match[0]], [adopt[1], override[1], wait[1], match[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing params\n",
    "epsilon = 10e-5\n",
    "T = 70\n",
    "gamma = 0\n",
    "alpha = 0.4\n",
    "\n",
    "# the numbers of states is (T+1)*(T+1)*3 because each chain can be up to T length and there are 3 fork states.\n",
    "num_states = (T+1)*(T+1)*3\n",
    "\n",
    "# generate a state to integer mapping and list of states\n",
    "state_mapping = {}\n",
    "states = []\n",
    "count = 0\n",
    "for a in range(T+1):\n",
    "    for h in range(T+1):\n",
    "        for fork in ['irrelevant', 'relevant', 'active']:\n",
    "            state_mapping[(a, h, fork)] = count\n",
    "            states.append((a, h, fork))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0; high = 1\n",
    "while (high - low) >= epsilon / 8:\n",
    "    rho = (low + high) / 2\n",
    "    matrices = getAllMatrices(rho, underpaying=True)\n",
    "    rvi = mdptoolbox.mdp.RelativeValueIteration(matrices[0], matrices[1], epsilon/8)\n",
    "    rvi.run()\n",
    "    if rvi.average_reward > 0:\n",
    "        low = rho\n",
    "    else:\n",
    "        high = rho\n",
    "lower_bound = rho - epsilon\n",
    "rho_prime = np.max(low - epsilon/4, 0)\n",
    "matrices = getAllMatrices(rho_prime, underpaying=False)\n",
    "rvi = mdptoolbox.mdp.RelativeValueIteration(matrices[0], matrices[1], epsilon)\n",
    "rvi.run()\n",
    "rvi.average_reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
