{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 10e-5\n",
    "T = 70\n",
    "gamma = 0\n",
    "alpha = 0.4\n",
    "rho = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numbers of states is (T+1)*(T+1)*3 because each chain can be up to T length and there are 3 fork states.\n",
    "num_states = (T+1)*(T+1)*3\n",
    "\n",
    "# generate a state to integer mapping and list of states\n",
    "state_mapping = {}\n",
    "states = []\n",
    "count = 0\n",
    "for a in range(T+1):\n",
    "    for h in range(T+1):\n",
    "        for fork in ['irrelevant', 'relevant', 'active']:\n",
    "            state_mapping[(a, h, fork)] = count\n",
    "            states.append((a, h, fork))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the adopt transition & reward matrices\n",
    "adopt_transitions = np.zeros(shape = (num_states, num_states))\n",
    "adopt_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "# each adopt matrix only can map to (1,0,irrelevant) or (0,1,irrelevant)\n",
    "adopt_new_state_1_index = state_mapping[(1, 0, 'irrelevant')]\n",
    "adopt_new_state_2_index = state_mapping[(0, 1, 'irrelevant')]\n",
    "for state_index in range(num_states):\n",
    "    state = states[state_index]\n",
    "    adopt_transitions[state_index, adopt_new_state_1_index] = alpha\n",
    "    adopt_transitions[state_index, adopt_new_state_2_index] = 1 - alpha\n",
    "    adopt_rewards[state_index, adopt_new_state_1_index] = rho * state[1]\n",
    "    adopt_rewards[state_index, adopt_new_state_2_index] = rho * state[1]\n",
    "\n",
    "# making matrices sparse\n",
    "adopt_transitions = ss.csr_matrix(adopt_transitions)\n",
    "adopt_rewards = ss.csr_matrix(adopt_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the override transition & reward matrices\n",
    "override_transitions = np.zeros(shape = (num_states, num_states))\n",
    "override_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "for state_index in range(num_states):\n",
    "    state = states[state_index]\n",
    "    # a > h, which must be true for override to succeed\n",
    "    if state[0] > state[1]:\n",
    "        # (a-h, 0, irrelevant)\n",
    "        new_state_1 = (state[0]-state[1], 0, 'irrelevant')\n",
    "        # (a-h-1, 1, relevant)\n",
    "        new_state_2 = (state[0]-state[1]-1, 1, 'relevant')\n",
    "        override_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "        override_transitions[state_index, state_mapping[new_state_2]] = 1 - alpha\n",
    "        override_rewards[state_index, state_mapping[new_state_1]] = (1 - rho) * (state[1] + 1)\n",
    "        override_rewards[state_index, state_mapping[new_state_2]] = (1 - rho) * (state[1] + 1)\n",
    "        \n",
    "# making matrices sparse\n",
    "override_transitions = ss.csr_matrix(override_transitions)\n",
    "override_rewards = ss.csr_matrix(override_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the wait transition & reward matrices\n",
    "wait_transitions = np.zeros(shape = (num_states, num_states))\n",
    "wait_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "for state_index in range(num_states):\n",
    "    state = states[state_index]\n",
    "    # ignore truncated states\n",
    "    if (state[0] == T or state[1] == T):\n",
    "        continue\n",
    "    \n",
    "    # irrelevant or relevant\n",
    "    if (state[2] == 'irrelevant') or (state[2] == 'relevant'):\n",
    "        # (a+1, h, irrelevant)\n",
    "        new_state_1 = (state[0] + 1, state[1], 'irrelevant')\n",
    "        # (a, h+1, relevant)\n",
    "        new_state_2 = (state[0], state[1] + 1, 'relevant')\n",
    "        wait_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "        wait_transitions[state_index, state_mapping[new_state_2]] = 1 - alpha\n",
    "    # active\n",
    "    else:\n",
    "        # a >= h\n",
    "        if state[0] >= state[1]: \n",
    "            # (a+1, h, active)\n",
    "            new_state_1 = (state[0] + 1, state[1], 'active')\n",
    "            # (a-h, 1, relevant)\n",
    "            new_state_2 = (state[0] - state[1], 1, 'relevant')\n",
    "            # (a, h+1, relevant)\n",
    "            new_state_3 = (state[0], state[1] + 1, 'relevant')\n",
    "            wait_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "            wait_transitions[state_index, state_mapping[new_state_2]] = gamma * (1 - alpha)\n",
    "            wait_transitions[state_index, state_mapping[new_state_3]] = (1 - gamma) * (1 - alpha)\n",
    "            wait_rewards[state_index, state_mapping[new_state_2]] = (1 - rho) * state[1]\n",
    "            \n",
    "# making matrices sparse\n",
    "wait_transitions = ss.csr_matrix(wait_transitions)\n",
    "wait_rewards = ss.csr_matrix(wait_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the match transition & rewards matrices\n",
    "match_transitions = np.zeros(shape = (num_states, num_states))\n",
    "match_rewards = np.zeros(shape = (num_states, num_states))\n",
    "\n",
    "for state_index in range(num_states):\n",
    "    state = states[state_index]\n",
    "    # ignore truncated states\n",
    "    if (state[0] == T or state[1] == T):\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # a >= h and relevant\n",
    "    if (state[0] >= state[1]) and (state[2] == 'relevant'):\n",
    "        # (a+1, h, active)\n",
    "        new_state_1 = (state[0] + 1, state[1], 'active')\n",
    "        # (a-h, 1, relevant)\n",
    "        new_state_2 = (state[0] - state[1], 1, 'relevant')\n",
    "        # (a, h+1, relevant)\n",
    "        new_state_3 = (state[0], state[1] + 1, 'relevant')\n",
    "        match_transitions[state_index, state_mapping[new_state_1]] = alpha\n",
    "        match_transitions[state_index, state_mapping[new_state_2]] = gamma * (1 - alpha)\n",
    "        match_transitions[state_index, state_mapping[new_state_3]] = (1 - gamma) * (1 - alpha)\n",
    "        match_transitions[state_index, state_mapping[new_state_2]] = (1 - rho) * state[1]\n",
    "\n",
    "# making matrices sparse\n",
    "match_transitions = ss.csr_matrix(match_transitions)\n",
    "match_rewards = ss.csr_matrix(match_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.asarray([adopt_transitions, override_transitions, wait_transitions, match_transitions])\n",
    "reward_matrix = np.asarray([adopt_rewards, override_rewards, wait_rewards, match_rewards])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "StochasticError",
     "evalue": "'PyMDPToolbox - The transition probability matrix is not stochastic.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStochasticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-097fc701be05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdptoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRelativeValueIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/mdptoolbox/mdp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transitions, reward, epsilon, max_iter)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;31m# Initialise a relative value iteration MDP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m         \u001b[0mMDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/mdptoolbox/mdp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transitions, reward, discount, epsilon, max_iter)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# we run a check on P and R to make sure they are describing an MDP. If\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# an exception isn't raised then they are assumed to be correct.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0m_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_computeDimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_computeTransition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/mdptoolbox/util.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(P, R)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;31m# Check that the P's are square, stochastic and non-negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcheckSquareStochastic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetSpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/mdptoolbox/util.py\u001b[0m in \u001b[0;36mcheckSquareStochastic\u001b[0;34m(matrix)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0m_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSquareError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misStochastic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStochasticError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misNonNegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0m_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNonNegativeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStochasticError\u001b[0m: 'PyMDPToolbox - The transition probability matrix is not stochastic.'"
     ]
    }
   ],
   "source": [
    "mdptoolbox.mdp.RelativeValueIteration(transition_matrix, reward_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
