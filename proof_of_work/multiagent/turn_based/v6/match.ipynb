{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import environmentv6 as e\n",
    "import mdptoolbox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import progressbar as pb\n",
    "import scipy.sparse as ss\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ss.SparseEfficiencyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "alpha = 0.4\n",
    "T = 8\n",
    "state_count = (T+1) * (T+1)\n",
    "epsilon = 10e-5\n",
    "\n",
    "# game\n",
    "action_count = 3\n",
    "adopt = 0; override = 1; mine = 2\n",
    "\n",
    "# mapping utils\n",
    "state_mapping = {}\n",
    "states = []\n",
    "count = 0\n",
    "for a in range(T+1):\n",
    "    for h in range(T+1):\n",
    "            state_mapping[(a, h)] = count\n",
    "            states.append((a, h))\n",
    "            count += 1\n",
    "\n",
    "# initialize matrices\n",
    "transitions = []; rewards = []\n",
    "for _ in range(action_count):\n",
    "    transitions.append(ss.csr_matrix(np.zeros(shape=(state_count, state_count))))\n",
    "    rewards.append(ss.csr_matrix(np.zeros(shape=(state_count, state_count))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_cost = 0.52\n",
    "\n",
    "# populate matrices\n",
    "for state_index in range(state_count):\n",
    "    a, h = states[state_index]\n",
    "\n",
    "    # adopt transitions\n",
    "    transitions[adopt][state_index, state_mapping[0, 0]] = 1\n",
    "\n",
    "    # override\n",
    "    if a > h:\n",
    "        transitions[override][state_index, state_mapping[a-h-1, 0]] = 1\n",
    "        rewards[override][state_index, state_mapping[a-h-1, 0]] = h + 1\n",
    "    else:\n",
    "        transitions[override][state_index, 0] = 1\n",
    "        rewards[override][state_index, 0] = -10000\n",
    "\n",
    "    # mine transitions\n",
    "    if (a < T) and (h < T):\n",
    "        transitions[mine][state_index, state_mapping[a+1, h]] = alpha\n",
    "        transitions[mine][state_index, state_mapping[a, h+1]] = (1 - alpha) \n",
    "        rewards[mine][state_index, state_mapping[a+1, h]] = -1 * alpha * mining_cost\n",
    "        rewards[mine][state_index, state_mapping[a, h+1]] = -1 * alpha * mining_cost\n",
    "#         transitions[mine][state_index, state_mapping[a, h]] = 1 - (1 - alpha) * difficulty  - alpha * difficulty\n",
    "#         reward[mine][state_index, state_mapping[a, h]] = -1 * alpha * mining_cost\n",
    "        \n",
    "    else:\n",
    "        transitions[mine][state_index, 0] = 1\n",
    "        rewards[mine][state_index, 0] = -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvi = mdptoolbox.mdp.RelativeValueIteration(transitions, rewards, epsilon/8)\n",
    "rvi.run()\n",
    "policy = rvi.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEhCAYAAAAwHRYbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE59JREFUeJzt3V9MVHfex/EPZzBR8UYYie5MCiJiqhfahKCBxD/RMKGWuE0babKN1Vp3Uw1qb5S0hpvGGpJuKrskm+fCdTXRBOt2XbKJtY3RG8UU2iaWSFxJ3DYzgDBQb0QSKPNcwC61eZaHQX/n68x5v64smTMfvue0nx5Gfr+Tk0qlBABWPOtvAECwUUIATFFCAExRQgBMUUIATFFCAExRQgBMUUIATFFCAEzlpvPiif4y33+9OvartX5HAngGvpz4NGc2r+NOCIApSgiAKUoIgClKCIApSgiAKUoIgClKCIApSgiAKUoIgClKCIAppyXUNyC9dUh6ZZf0ylvS2Ysu055UHlunP3c36y///KPqjv46q3ODNGvQcoMwq9MSCoWkIwekf5yVWv8knf+b1PMvl4mTPM9Tfctevf/ycb2z5j1teaNKL7wYzcrcIM0atNygzOq0hAoLpDVlk3/OWyitKJIeDLpMnLSqolS9Pf3qvz+g8bFxXW+9ocod5VmZG6RZg5YblFl9+0wo0Sd135PWrnafFY7kazA+9J9/TsaHFY4UZGVukGYNWm5QZvWlhB6NSAcbpYZ6aVGeH4kAMoXzEhoblw41SrXbpOqNrtMmJRPDWhKdbu5wNF/JxNAMR2RubpBmDVpuUGZ1WkKplHSsSSopknbXuUx60t2OHkVWLtPS4kLlzsvV5roqtbd1ZmVukGYNWm5QZk1rZ8V0ffOd1PZFjspKUnp17+TXDu+TNm1wmSpN/DShlvpTOvH5B/JCnq6cvqbv78TdhhrlBmnWoOUGZdacVGr2O7ayvSuA2WJ7VwAZgRICYIoSAmCKEgJgihICYIoSAmCKEgJgihICYIoSAmCKEgJgKq21Y6UXfufq+/ivenr/x/dMKyxRQRBxJwTAFCUEwBQlBMAUJQTAFCUEwBQlBMAUJQTAFCUEwBQlBMCU8xJq2hrTV++8q8u/ect11H/0DUhvHZJe2SW98pZ09mJ255bH1unP3c36yz//qLqjv/YnlNyszfQ713kJXezu0p6//9V1zBNCIenIAekfZ6XWP0nn/yb1/Cs7cz3PU33LXr3/8nG9s+Y9bXmjSi+8GHUbSq4vuUGZ1XkJdfQm9HB01HXMEwoLpDVlk3/OWyitKJIeDGZn7qqKUvX29Kv//oDGx8Z1vfWGKneUuw0l15fcoMya9Z8JJfqk7nvS2tXZmRuO5GswPv2I3mR8WOFIwQxHkJspuUGZNatL6NGIdLBRaqiXFuVlfy6QibK2hMbGpUONUu02qXpj9uYmE8NaEp3+v1Q4mq9kYmiGI8jNlNygzJqVJZRKSceapJIiaXdddufe7ehRZOUyLS0uVO68XG2uq1J7Wye5WZAblFnT2tRsLppj27U+GtXi+Qt04+3fqvnWTV240+U085vvpLYvclRWktKreye/dniftGmD01iT3ImfJtRSf0onPv9AXsjTldPX9P2duLtAcn3LDcqsOalUatYvLvnD72f/4mekZyc7KwKZ6MuJT3Nm87qs/HEMQOaghACYooQAmKKEAJiihACYooQAmKKEAJiihACYooQAmKKEAJhKa9nGRH+Z78s2Si/8zu9ISSwXAZ4WyzYAZARKCIApSgiAKUoIgClKCIApSgiAKUoIgClKCIApSgiAKUoIgCmnj/zpG5AajktDP0rKkXbWSrted5k4qWlrTFuWl2jo8Yhqzp1xHzjFYl6rcyxJ5bF12n9yj7yQp8unrqq16RK5WZDpd67TO6FQSDpyQPrHWan1T9L5v0k9/3KZOOlid5f2/P2v7oN+wWJeq3PseZ7qW/bq/ZeP650172nLG1V64cUouRmeaZHrtIQKC6Q1ZZN/zlsorSiSHgy6TJzU0ZvQw9FR90G/YDGv1TleVVGq3p5+9d8f0PjYuK633lDljnJyMzzTIte3z4QSfVL3PWntar8SbVnM62dmOJKvwfj088mT8WGFIwUzHEFuJmRa5PpSQo9GpIONUkO9tCjPj0RbFvMG7RwjezgvobFx6VCjVLtNqt7oOs2exbwWmcnEsJZEp//vGI7mK5kYmuEIcjMh0yLXaQmlUtKxJqmkSNpd5zLp+WAxr9U5vtvRo8jKZVpaXKjcebnaXFel9rZOcjM80yLX6V/Rf/Od1PZFjspKUnp17+TXDu+TNm1wmSo1x7ZrfTSqxfMX6Mbbv1XzrZu6cKfLbahs5rU6xxM/Tail/pROfP6BvJCnK6ev6fs7cbehAcsNyqxs7/pfsL0r8HTY3hVARqCEAJiihACYooQAmKKEAJiihACYooQAmKKEAJiihACYooQAmHrul21YsVguEqSlIpZYpuIPlm0AyAiUEABTlBAAU5QQAFOUEABTlBAAU5QQAFOUEABTlBAAU5QQAFNOH/nTNyA1HJeGfpSUI+2slXa97jLRNrdpa0xblpdo6PGIas6dcR+o4J1jq1xJKo+t0/6Te+SFPF0+dVWtTZeyMtPvXKclFApJRw5Ia8omH1P82j6pslwqLXaZapd7sbtLZ29/q4+ra9wG/UzQzrFVrud5qm/Zq6PVHyoZH1bLVyfU3tapH7rdPY/LItMi1+mPY4UFk/+ySFLeQmlFkfRg0GWibW5Hb0IPR0fdB/1M0M6xVe6qilL19vSr//6AxsfGdb31hip3lGddpkWub58JJfqk7nvS2tV+JdrmWgjaOfYzNxzJ12B8+nnsyfiwwpGCGY7IzEyLXF9K6NGIdLBRaqiXFuX5kWibayFo5zhI1zbbOS+hsXHpUKNUu02q3ug6zT7XQtDOsUVuMjGsJdHpu4FwNF/JxNAMR2RmpkWu0xJKpaRjTVJJkbS7zmXS85FrIWjn2Cr3bkePIiuXaWlxoXLn5WpzXZXa2zqzLtMi1+nfjn3zndT2RY7KSlJ6de/k1w7vkzZtcJlql9sc26710agWz1+gG2//Vs23burCnS6nmUE7x1a5Ez9NqKX+lE58/oG8kKcrp6/p+ztu/5bKItMil+1d/wu2d81ebO/qD7Z3BZARKCEApighAKYoIQCmKCEApighAKYoIQCmKCEApighAKYoIQCmWLbxHLFYKiKxXMQvQVsuwrINABmBEgJgihICYIoSAmCKEgJgihICYIoSAmCKEgJgihICYIoSAmDK6SN/+gakhuPS0I+ScqSdtdKu110mBjO3aWtMW5aXaOjxiGrOnXEfqOCdY6vc8tg67T+5R17I0+VTV9XadMl9qM+5TksoFJKOHJDWlE0+tve1fVJluVRa7DI1eLkXu7t09va3+ri6xm3QzwTtHFvkep6n+pa9Olr9oZLxYbV8dULtbZ36odvts8f8znX641hhweRFk6S8hdKKIunBoMvEYOZ29Cb0cHTUfdDPBO0cW+SuqihVb0+/+u8PaHxsXNdbb6hyR7nbUINc3z4TSvRJ3fektav9SgxmroWgnWO/csORfA3Gp58Bn4wPKxwpmOGIzMz1pYQejUgHG6WGemlRnh+Jwcy1ELRzHKRr6xfnJTQ2Lh1qlGq3SdUbXacFN9dC0M6x37nJxLCWRKfvQMLRfCUTQzMckZm5TksolZKONUklRdLuOpdJwc61ELRzbJF7t6NHkZXLtLS4ULnzcrW5rkrtbZ1Zl+t0Z8Wvb0tv1ueorCQlb6ruDu+TNm1I63tMW6bmznVnxebYdq2PRrV4/gIlH4+o+dZNXbjTNevj57KzYqaeY8vcueysWFHzkt79ZLe8kKcrp6/p/Eefpf0ec/Escme7syLbuz5H2N41u7G96/+N35gGYIoSAmCKEgJgihICYIoSAmCKEgJgihICYIoSAmCKEgJgihICYIplG2C5SBazXCrCsg0AGYESAmCKEgJgihICYIoSAmCKEgJgihICYIoSAmCKEgJgyumz6PsGpIbj0tCPknKknbXSrtddJgYv12pWSWraGtOW5SUaejyimnNnfMnk2rrN/Lfy2DrtP7lHXsjT5VNX1dp0yVmW0xIKhaQjByaf4f1oRHptn1RZLpUWu0wNVq7VrJJ0sbtLZ29/q4+ra9yHTeHaup/V8zzVt+zV0eoPlYwPq+WrE2pv69QP3XE3eU7edUphweQJlKS8hdKKIunBoMvE4OVazSpJHb0JPRwd9SdsCtfWbaYkraooVW9Pv/rvD2h8bFzXW2+ocke5szzfPhNK9End96S1q/1KDF6u1axWuLZuhCP5GoxPP/Y5GR9WOFIwwxFPx5cSejQiHWyUGuqlRXl+JAYv12pWK1zb7OG8hMbGpUONUu02qXqj67Rg5lrNaoVr61YyMawl0ek7n3A0X8nE0AxHPB2nJZRKSceapJIiaXedy6Tg5lrNaoVr697djh5FVi7T0uJC5c7L1ea6KrW3dTrLc7qp2de3pTfrc1RWkpI3VXeH90mbNqT1PaYtSLnPInOum5o1x7ZrfTSqxfMXKPl4RM23burCna5ZHz+XTc24tullznVTs4qal/TuJ7vlhTxdOX1N5z/6LO33mO2mZuysCHZWzGLsrAgA/w9KCIApSgiAKUoIgClKCIApSgiAKUoIgClKCIApSgiAKUoIgClKCIApp9u7IjNYreFizRok7oQAGKOEAJiihACYooQAmKKEAJiihACYooQAmKKEAJiihACYcvob030DUsNxaehHSTnSzlpp1+suE4OXG6RZJalpa0xblpdo6PGIas6dcR84JUjXVpLKY+u0/+QeeSFPl09dVWvTJWdZTksoFJKOHJDWlE0+yva1fVJluVRa7DI1WLlBmlWSLnZ36eztb/VxdY3boF8I0rX1PE/1LXt1tPpDJePDavnqhNrbOvVDd9xNnpN3nVJYMHkCJSlvobSiSHow6DIxeLlBmlWSOnoTejg66j7oF4J0bVdVlKq3p1/99wc0Pjau6603VLmj3Fmeb58JJfqk7nvS2tV+JQYvN0izWsr2axuO5GswPv3s+WR8WOFIwQxHPB1fSujRiHSwUWqolxbl+ZEYvNwgzWopSNfWL85LaGxcOtQo1W6Tqje6TgtmbpBmtRSUa5tMDGtJdPrOJxzNVzIxNMMRT8dpCaVS0rEmqaRI2l3nMim4uUGa1VKQru3djh5FVi7T0uJC5c7L1ea6KrW3dTrLy0mlUrN+8UR/2exfLOnr29Kb9TkqK0nJm6q7w/ukTRvS+h7TFqTcTJ51LpuaNce2a300qsXzFyj5eETNt27qwp2utN5jLpuaZeq1jf1q7ZyyK2pe0ruf7JYX8nTl9DWd/+iztN/jy4lPc2bzOqclBMyEnRXdm2sJPQuzLSF+YxqAKUoIgClKCIApSgiAKUoIgClKCIApSgiAKUoIgClKCIApSgiAKac7KwIzsVo+wXKR5wt3QgBMUUIATFFCAExRQgBMUUIATFFCAExRQgBMUUIATFFCAExRQgBMOV220TcgNRyXhn6UlCPtrJV2ve4yMXi5QZrVMrdpa0xblpdo6PGIas6dcR8ou1klqTy2TvtP7pEX8nT51FW1Nl1yluW0hEIh6cgBaU3Z5KNsX9snVZZLpcUuU4OVG6RZLXMvdnfp7O1v9XF1jdugn7Ga1fM81bfs1dHqD5WMD6vlqxNqb+vUD91xN3lO3nVKYcHkCZSkvIXSiiLpwaDLxODlBmlWy9yO3oQejo66D/oZq1lXVZSqt6df/fcHND42ruutN1S5o9xZnm+fCSX6pO570trVfiUGLzdIs1rmWvBz1nAkX4Px6WfPJ+PDCkcKZjji6fhSQo9GpIONUkO9tCjPj8Tg5QZpVstcC9k+q/MSGhuXDjVKtduk6o2u04KZG6RZLXMtWMyaTAxrSXT6zicczVcyMTTDEU/HaQmlUtKxJqmkSNpd5zIpuLlBmtUy14LVrHc7ehRZuUxLiwuVOy9Xm+uq1N7W6SwvJ5VKzfrFE/1ls3+xpK9vS2/W56isJCVvqu4O75M2bUjre0xbkHKDNOuzyp3LzorNse1aH41q8fwFSj4eUfOtm7pwpyut90h3Z8VnMWvsV2vTyvy3ipqX9O4nu+WFPF05fU3nP/os7ff4cuLTnNm8zmkJAc+jIG3vOtcSehZmW0L8xjQAU5QQAFOUEABTlBAAU5QQAFOUEABTlBAAU5QQAFOUEABTlBAAU2ntrGj16+5ANrD472eFbvmemS7uhACYooQAmKKEAJiihACYooQAmKKEAJiihACYooQAmKKEAJiihACYSmvZxlw0bY1py/ISDT0eUc25M67jzDLJ5dpmU255bJ32n9wjL+Tp8qmram265CzL+Z3Qxe4u7fn7X13HmGeSm72ZQcv1PE/1LXv1/svH9c6a97TljSq98GLUXZ6zd57S0ZvQw9FR1zHmmeRmb2bQcldVlKq3p1/99wc0Pjau6603VLmj3FkenwkBeEI4kq/B+PSz55PxYYUjBTMc8XQoIQCmKCEAT0gmhrUkOn3nE47mK5kYmuGIp0MJAXjC3Y4eRVYu09LiQuXOy9Xmuiq1t3U6y8tJpVKzfnHJH34/+xdPaY5t1/poVIvnL1Dy8Yiab93UhTtd6b7Nc59JLtf2ecxdcXhuOytW1Lykdz/ZLS/k6crpazr/0Wdpv8eXE5/mzOZ1zksIgJ25ltCzMNsS4scxAKYoIQCmKCEApighAKYoIQCmKCEApighAKYoIQCmKCEApighAKbSWrYBAM8ad0IATFFCAExRQgBMUUIATFFCAExRQgBMUUIATFFCAExRQgBMUUIATP0vb0ZF9AIJiYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.imshow(np.reshape(policy, (9,9)))\n",
    "ax = sns.heatmap(np.reshape(policy, (9,9)), annot=True, cmap='viridis')\n",
    "cb = ax.collections[-1].colorbar   \n",
    "cb.remove()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm1_policy = np.asarray([\n",
    "[2, 0, 9, 9, 9, 9, 9, 9, 9],\n",
    "[2, 0, 9, 9, 9, 9, 9, 9, 9],\n",
    "[2, 1, 0, 9, 9, 9, 9, 9, 9], \n",
    "[2, 2, 1, 0, 9, 9, 9, 9, 9],\n",
    "[2, 2, 2, 1, 0, 9, 9, 9, 9],\n",
    "[2, 2, 2, 2, 1, 0, 9, 9, 9],\n",
    "[2, 2, 2, 2, 2, 1, 0, 9, 9],\n",
    "[2, 2, 2, 2, 2, 2, 1, 0, 9],\n",
    "[1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
    "])\n",
    "\n",
    "honest_policy = np.asarray([\n",
    "[2, 0, 9, 9, 9, 9, 9, 9, 9],\n",
    "[1, 9, 9, 9, 9, 9, 9, 9, 9],\n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9], \n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
    "[9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "])\n",
    "\n",
    "opt_policy = np.reshape(policy, (9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt_policy(alpha, T, mining_cost):\n",
    "    for state_index in range(state_count):\n",
    "        a, h = states[state_index]\n",
    "\n",
    "        # adopt transitions\n",
    "        transitions[adopt][state_index, state_mapping[0, 0]] = 1\n",
    "\n",
    "        # override\n",
    "        if a > h:\n",
    "            transitions[override][state_index, state_mapping[a-h-1, 0]] = 1\n",
    "            rewards[override][state_index, state_mapping[a-h-1, 0]] = h + 1\n",
    "        else:\n",
    "            transitions[override][state_index, 0] = 1\n",
    "            rewards[override][state_index, 0] = -10000\n",
    "\n",
    "        # mine transitions\n",
    "        if (a < T) and (h < T):\n",
    "            transitions[mine][state_index, state_mapping[a+1, h]] = alpha\n",
    "            transitions[mine][state_index, state_mapping[a, h+1]] = (1 - alpha) \n",
    "            rewards[mine][state_index, state_mapping[a+1, h]] = -1 * alpha * mining_cost\n",
    "            rewards[mine][state_index, state_mapping[a, h+1]] = -1 * alpha * mining_cost        \n",
    "        else:\n",
    "            transitions[mine][state_index, 0] = 1\n",
    "            rewards[mine][state_index, 0] = -10000\n",
    "        \n",
    "        rvi = mdptoolbox.mdp.RelativeValueIteration(transitions, rewards, epsilon/8)\n",
    "        rvi.run()\n",
    "        return np.reshape(rvi.policy, (T+1, T+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 1, 2, 2, 2, 0, 0, 0, 0],\n",
       "       [2, 2, 1, 2, 2, 2, 0, 0, 0],\n",
       "       [2, 2, 2, 1, 2, 2, 2, 0, 0],\n",
       "       [2, 2, 2, 2, 1, 2, 2, 2, 0],\n",
       "       [2, 2, 2, 2, 2, 1, 2, 2, 0],\n",
       "       [2, 2, 2, 2, 2, 2, 1, 2, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_opt_policy(alpha=0.4, T=8, mining_cost=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000000 of 1000000) |##############| Elapsed Time: 0:00:28 Time:  0:00:28\n"
     ]
    }
   ],
   "source": [
    "# simulation\n",
    "length = int(1e6)\n",
    "alpha = 0.4\n",
    "T = 8\n",
    "mining_cost = 0.5\n",
    "env = e.Environment(alpha, T, mining_cost)\n",
    "\n",
    "# simulation\n",
    "bar = pb.ProgressBar()\n",
    "_ = env.reset()\n",
    "current_reward = 0\n",
    "for _ in bar(range(length)):\n",
    "    a, h = env.current_state\n",
    "    action = opt_policy[(a,h)]\n",
    "    _, reward = env.takeAction(action)\n",
    "    current_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101211.00000130651 0.10121100000130652\n"
     ]
    }
   ],
   "source": [
    "# opt\n",
    "print(current_reward, current_reward / length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54266.60000058278 0.05426660000058278\n"
     ]
    }
   ],
   "source": [
    "# sm1\n",
    "print(current_reward, current_reward / length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100698.00000089758 0.10069800000089758\n"
     ]
    }
   ],
   "source": [
    "# honest\n",
    "print(current_reward, current_reward / length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
